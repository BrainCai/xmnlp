{
  "name": "nlp：xmnlp",
  "tagline": "xmnlp中文分词工具，java编写，统计概率分词+规则分词实现，功能包括人名识别，词性标注，用户自定义词典扩展，分词效果速度都超过开源版的jieba分词。 ",
  "body": "# xmnlp自然语言处理包\r\n\r\n\r\n#### author：xuming(shibing624)\r\n#### environment：jdk 1.6\r\n\r\n**xmnlp**是由一系列模型与算法组成的Java工具包，目标是普及自然语言处理在生产环境中的应用。**xmnlp**具备功能完善、性能高效、架构清晰、语料时新、可自定义的特点。\r\n\r\n**xmnlp**提供下列功能：\r\n\r\n> * 中文分词.\r\n  * 最短路分词.\r\n  * N-最短路分词\r\n  * CRF分词.\r\n  * 索引分词.\r\n  * 极速词典分词.\r\n  * 用户自定义词典.\r\n> * 词性标注.\r\n> * 命名实体识别.\r\n  * 中国人名识别.\r\n  * 音译人名识别.\r\n  * 日本人名识别.\r\n  * 地名识别.\r\n  * 实体机构名识别.\r\n> * 关键词提取.\r\n  * TextRank关键词提取.\r\n> * 自动摘要.\r\n  * TextRank自动摘要.\r\n> * 短语提取.\r\n  * 基于互信息和左右信息熵的短语提取.\r\n> * 拼音转换.\r\n  * 多音字.\r\n  * 声母.\r\n  * 韵母.\r\n  * 声调.\r\n> * 简繁转换.\r\n  * 繁体中文分词.\r\n  * 简繁分歧词.\r\n> * 文本推荐.\r\n  * 语义推荐.\r\n  * 拼音推荐.\r\n  * 字词推荐.\r\n> * 依存句法分析.\r\n  * 基于神经网络的高性能依存句法分析器.\r\n  * MaxEnt依存句法分析.\r\n  * CRF依存句法分析.\r\n> * 语料库工具.\r\n  * 分词语料预处理.\r\n  * 词频词性词典制作.\r\n  * BiGram统计.\r\n  * 词共现统计.\r\n  * CoNLL语料预处理.\r\n\r\n\r\n在提供丰富功能的同时，**xmnlp**内部模块坚持低耦合、模型坚持惰性加载、服务坚持静态提供、词典坚持明文发布，使用非常方便，同时自带一些语料处理工具，帮助用户训练自己的语料。\r\n\r\n------\r\n\r\n\r\n\r\n## 如何获取\r\n  - 方式一：当前稳定版本\r\n\r\n    ```\r\n  \t<dependency>\r\n            <groupId>com.xm</groupId>\r\n            <artifactId>xmnlp</artifactId>\r\n            <version>1.2</version>\r\n    </dependency>\r\n  \t```\r\n\r\n    零配置，即可使用基本功能（除CRF分词、依存句法分析外的全部功能）。如果用户有自定义的需求，可以参考方式二，使用xmnlp.properties进行配置。\r\n\r\n  - 方式二：下载jar、data、xmnlp.properties\r\n\r\n  \t数据与程序分离，给予用户自定义的自由。\r\n\r\n  \t1、下载jar\r\n\r\n  \t  xmnlp.jar\r\n\r\n  \t2、下载data\r\n\r\n\t  [data.zip](http://pan.baidu.com/s/1jIydVsq)\r\n\t  下载后解压到任意目录，接下来通过配置文件告诉xmnlp数据包的位置。\r\n\r\n\t  xmnlp中的数据分为词典和模型，其中词典是词法分析必需的，模型是句法分析必需的。\r\n\r\n\r\n\t>\r\n\t> \t  data\r\n\t> \t  │\r\n\t> \t  ├─dictionary\r\n\t> \t  └─model\r\n\r\n\t  用户可以自行增删替换，如果不需要句法分析功能的话，随时可以删除model文件夹。\r\n\r\n\t  模型跟词典没有绝对的区别，隐马模型被做成人人都可以编辑的词典形式，不代表它不是模型。\r\n\t  GitHub代码库中已经包含了data.zip中的词典，直接编译运行自动缓存即可；模型则需要额外下载。\r\n\r\n  \t3、配置文件\r\n\r\n\t  示例配置文件:`xmnlp.properties` 在src的resources中。\r\n\r\n\t  配置文件的作用是告诉xmnlp数据包的位置，只需修改第一行\r\n\r\n\t  root=usr/home/xmnlp/\r\n\t  为data的父目录即可，比如data目录是/Users/root/Documents/data，那么root=/Users/root/Documents/ 。\r\n\r\n\t  如果选用mini词典的话，则需要修改配置文件：\r\n\r\n\t  CoreDictionaryPath=data/dictionary/CoreNatureDictionary.mini.txt\r\n\t  BiGramDictionaryPath=data/dictionary/CoreNatureDictionary.ngram.mini.txt\r\n\r\n\t  最后将xmnlp.properties放入classpath即可，对于任何项目，都可以放到src或resources目录下，编译时IDE会自动将其复制到classpath中。\r\n\r\n\t  如果放置不当，xmnlp会智能提示当前环境下的合适路径，并且尝试从项目根目录读取数据集。\r\n\r\n## 调用方法\r\n\r\n**xmnlp**几乎所有的功能都可以通过工具类`Xmnlp`快捷调用，当你想不起来调用方法时，只需键入`Xmnlp.`，IDE应当会给出提示，并展示**xmnlp**完善的文档。\r\n\r\n*推荐用户始终通过工具类`Xmnlp`调用，这么做的好处是，将来**xmnlp**升级后，用户无需修改调用代码。*\r\n\r\n所有Demo都位于[org.xm.xmnlp.demo](https://github.com/shibing624/xmnlp/tree/master/src/test/java/org/xm/xmnlp/demo)下，比文档覆盖了更多细节，强烈建议运行一遍。\r\n\r\n#### 如何使用\r\n\r\n  - Demo\r\n\t```\r\n\tSystem.out.println(Xmnlp.segment(\"你好，欢迎使用xmnlp自然语言处理包！\"));\r\n\t```\r\n\r\n## 支持结巴中文分词模式\r\n   - Search模式，用于对用户查询词分词\r\n   - Index模式，用于对索引文档分词\r\n\r\n#### 特性\r\n   - 支持多种分词模式\r\n   - 全角统一转成半角\r\n   - 用户词典功能\r\n   - resource 目录有整理的搜狗细胞词库和一个自定义词库，可加载多个用户词库\r\n\r\n#### 算法\r\n  - [ ] 基于 =trie= 树结构实现高效词图扫描\r\n  - [ ] 生成所有切词可能的有向无环图 =DAG=\r\n  - [ ] 采用动态规划算法计算最佳切词组合\r\n  - [ ] 基于 =HMM= 模型，采用 =Viterbi= (维特比)算法实现未登录词识别\r\n\r\n## 许可证\r\n  许可证为ApacheLicence 2.0\r\n\r\n## 感谢\r\n  HanLP作者、ansj作者、jieba作者",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}